{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49558527",
   "metadata": {},
   "source": [
    "# A DIALOGUE between HAL and ME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9301d0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from HAL.literate import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6726d98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of answers: 5 \n",
      "-------------\n",
      "\n",
      "\n",
      "ADAMS, The Restaurant At The End Of The World:\n",
      "\t\t‘Oh, hello there,’ he said to them.\n",
      "---\n",
      "\n",
      "\n",
      "\n",
      "ADAMS, The Hitchikers Guide To The Galaxy:\n",
      "\t\tOf all the races in all the Galaxy who could have come and said a big hello to planet Earth, he thought, didn’t it just have to be the Vogons.\n",
      "---\n",
      "\n",
      "\n",
      "\n",
      "ADAMS, The Hitchikers Guide To The Galaxy:\n",
      "\t\tand news reports brought to you here on the sub etha waveband, broadcasting around the Galaxy around the clock,’ squawked a voice, ‘and we’ll be saying a big hello to all intelligent life forms everywhere...\n",
      "---\n",
      "\n",
      "\n",
      "\n",
      "ADAMS, The Hitchikers Guide To The Galaxy:\n",
      "\t\t‘Why hello there!’ they said (ticker tape, ticker tape).\n",
      "---\n",
      "\n",
      "\n",
      "\n",
      "ADAMS, Mostly Harmless:\n",
      "\t\t‘No, I mean, that sounded like someone I knew.’ ‘Princess Hooli? If I had to stand around saying hello to everybody who’s known Princess Hooli I’d need a new set of lungs.’ ‘Not the Princess,’ said Arthur.\n",
      "---\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "theka = 'hitchhikers_guide'\n",
    "topic = 'city'\n",
    "question = 'hello'\n",
    "\n",
    "\n",
    "library = Library.from_library_folder(theka)\n",
    "answers = library.ask(topic, question, print_answers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f99b7e1",
   "metadata": {},
   "source": [
    "ask somethink to HAL \n",
    "\n",
    "he will anwer\n",
    "\n",
    "with a cacophony of voices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5b1a69f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "PowerIterationFailedConvergence",
     "evalue": "(PowerIterationFailedConvergence(...), 'power iteration failed to converge within 100 iterations')",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPowerIterationFailedConvergence\u001b[39m           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 41\u001b[39m\n\u001b[32m     38\u001b[39m g = Graph()\n\u001b[32m     39\u001b[39m g.build_graph_from_rules(connectivity)\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m eigen_centrality = \u001b[43mnx\u001b[49m\u001b[43m.\u001b[49m\u001b[43meigenvector_centrality\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m node1, node2 \u001b[38;5;129;01min\u001b[39;00m g.graph.edges():\n\u001b[32m     44\u001b[39m     centrality_value = (eigen_centrality[node1] + eigen_centrality[node2]) / \u001b[32m2\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<class 'networkx.utils.decorators.argmap'> compilation 5:4\u001b[39m, in \u001b[36margmap_eigenvector_centrality_1\u001b[39m\u001b[34m(G, max_iter, tol, nstart, weight, backend, **backend_kwargs)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcollections\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgzip\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01minspect\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mitertools\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mre\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\computer-1\\Desktop\\HAL\\.venv\\Lib\\site-packages\\networkx\\utils\\backends.py:967\u001b[39m, in \u001b[36m_dispatchable.__call__\u001b[39m\u001b[34m(self, backend, *args, **kwargs)\u001b[39m\n\u001b[32m    965\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m backend != \u001b[33m\"\u001b[39m\u001b[33mnetworkx\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    966\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m backend is not installed\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m967\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43morig_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[38;5;66;03m# Use `backend_name` in this function instead of `backend`.\u001b[39;00m\n\u001b[32m    970\u001b[39m \u001b[38;5;66;03m# This is purely for aesthetics and to make it easier to search for this\u001b[39;00m\n\u001b[32m    971\u001b[39m \u001b[38;5;66;03m# variable since \"backend\" is used in many comments and log/error messages.\u001b[39;00m\n\u001b[32m    972\u001b[39m backend_name = backend\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\computer-1\\Desktop\\HAL\\.venv\\Lib\\site-packages\\networkx\\algorithms\\centrality\\eigenvector.py:194\u001b[39m, in \u001b[36meigenvector_centrality\u001b[39m\u001b[34m(G, max_iter, tol, nstart, weight)\u001b[39m\n\u001b[32m    192\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mabs\u001b[39m(x[n] - xlast[n]) \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m x) < nnodes * tol:\n\u001b[32m    193\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m nx.PowerIterationFailedConvergence(max_iter)\n",
      "\u001b[31mPowerIterationFailedConvergence\u001b[39m: (PowerIterationFailedConvergence(...), 'power iteration failed to converge within 100 iterations')"
     ]
    }
   ],
   "source": [
    "from HAL.literate import *\n",
    "from HAL.pixels import Color\n",
    "from HAL.metrika import Graph\n",
    "\n",
    "\n",
    "\n",
    "def get_connections_of_a_question(question):\n",
    "\n",
    "    theka = 'urbotheka'\n",
    "    topic = question\n",
    "\n",
    "\n",
    "    library = Library.from_library_folder(theka)\n",
    "    answers = library.ask(topic,  question, print_answers=False);\n",
    "\n",
    "\n",
    "    quotebook = Quotebook(answers)\n",
    "    text, footnotes, title = quotebook.build_text(create_title=True, n=30)\n",
    "\n",
    "    narrative = filter_by_places(text)\n",
    "    narrative = clean_whitespaces(narrative)\n",
    "    connections = get_connection_of_word(narrative)\n",
    "\n",
    "    return connections\n",
    "\n",
    "\n",
    "\n",
    "questions = ['station', 'museum', 'house']\n",
    "\n",
    "\n",
    "connectivity = Rule([])\n",
    "\n",
    "for q in questions:\n",
    "    conn = get_connections_of_a_question(q)\n",
    "    connectivity.merge(conn)\n",
    "\n",
    "\n",
    "g = Graph()\n",
    "g.build_graph_from_rules(connectivity)\n",
    "\n",
    "eigen_centrality = nx.eigenvector_centrality(g.graph)\n",
    "\n",
    "for node1, node2 in g.graph.edges():\n",
    "    centrality_value = (eigen_centrality[node1] + eigen_centrality[node2]) / 2\n",
    "    g.add_edge_attribute(node1, node2, 'eigen', centrality_value)\n",
    "\n",
    "\n",
    "g.draw(show_nodes=False, label_color=Color.WHITE, edge_color=Color.WHITE, label_size=30, edge_direction=False, graph_type=\"KAMADA-KAWAI\", spectral_weight='eigen')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7297ed5a",
   "metadata": {},
   "source": [
    "From a text to a connection of words, they form a network of connections"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
